[simulation]

# perform 10 generations of evolutionary search for each new datum 
generations_per_datum = 10

# p(example i, i < n, being in the likelihood before seeing example n) = decay^(n-1 - i)
decay = 0.9

# the location of the data data, DSL, etc.
problem_dir = "./trs/head"

# learned TRSs must be deterministic
deterministic = true

# learn from 20 examples
n_examples = 20

[genetic]

# sampled terms can have at most 10 subterms
max_sample_size = 10 

# crossover generates just 1 new hypothesis.
n_crosses = 1

# keep a rule during crossover with probability 0.5.
p_keep = 0.5

# equally weight existing variables, operators with arity 0, operators with arity > 0, and invented variables
atom_weights = [1.0, 1.0, 1.0, 1.0]

[gp]

# selection occurs by randomly sampling from the current population + offspring without replacement.
selection = { "drift" = 0.0 }

# maintain a population of 10 individuals
population_size = 10 

# to find a parent, randomly select 3 from the existing population, then choose the best of those.
tournament_size = 3

# mutate 95% of the time, cross 5% of the time
mutation_prob = 0.95

# generate 90 new offspring during each generation
n_delta = 90

[model]

# the prior is generative: sample the number of rules and then sample each rule up to that number.
prior = { "SimpleGenerative" = {p_rule = 0.5, atom_weights = [1.0, 1.0, 1.0, 1.0]}}

# the likelihood is generative: rewrite the observed input according to your
# hypothesis and scale the probability of each computed output by the cost of
# probabilistically corrupting it into the observed output.
#
# NOTE: It's annoying, but you need to manually normalize the parameters so that:
#       - p_insertion = weight1/n_chars
#       - p_incorrect_sub = weight2/n_chars
#       - p_deletion + weight2 + p_correct_sub = 1.0
likelihood = { "List" = { t_max = 10, d_max = 10, dist = { beta = 0.005, p_insertion = 0.01, p_deletion = 0.0025, p_incorrect_sub = 0.000025, p_correct_sub = 0.995 }}}

# evaluation strategy is normal-order rather than eager, all possible rewrites, string rewriting, etc.
strategy = "Normal"

# nodes which are not leaves in an evaluation trace have probability 0.0
p_observe= 0.0

# evaluation traces have 25 steps or less
max_steps = 25

# terms in an evaluation trace have 110 subterms or less
max_size = 110 

# evaluation traces have depth 25 or less
max_depth = 25

# prior and likelihood are equally weighted in the posterior
p_temp = 1.0
l_temp = 1.0
